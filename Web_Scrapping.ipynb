#Scraping all the available attributes of weather data for each day from **2009-01-01 to 2018-10-28
#From Website: "http://www.estesparkweather.net/archive_reports.php?date=200901"

import bs4
from bs4 import BeautifulSoup
import csv
import requests
import time
import pandas as pd
import urllib
import re
import pickle
import datetime


labels=['Average temperature (°F)', 'Average humidity (%)',
 'Average dewpoint (°F)', 'Average barometer (in)',
 'Average windspeed (mph)', 'Average gustspeed (mph)',
 'Average direction (°deg)', 'Rainfall for month (in)',
 'Rainfall for year (in)', 'Maximum rain per minute',
 'Maximum temperature (°F)', 'Minimum temperature (°F)',
 'Maximum humidity (%)', 'Minimum humidity (%)', 'Maximum pressure',
 'Minimum pressure', 'Maximum windspeed (mph)',
 'Maximum gust speed (mph)', 'Maximum heat index (°F)']


Dates_r = pd.date_range(start = '1/1/2009',end = '28/11/2018',freq = 'M')
dates = [str(i)[:4] + str(i)[5:7] for i in Dates_r]
df_list=[]
index=[]

for k in range(len(dates)):
    if(k==117):
        url = "http://www.estesparkweather.net/archive_reports.php?date="
        url =url+dates[k]
        page = requests.get(url)
        soup =  BeautifulSoup(page.content,'html.parser')
        table = soup.find_all('table')
        raw_data = [row.text.splitlines() for row in table]
        raw_data = raw_data[:-9]
        for i in range(len(raw_data)):
            raw_data[i] = raw_data[i][2:len(raw_data[i]):3]
    
    
        for i in range(28):
            c = ['.'.join(re.findall("\d+",str(raw_data[i][j].split()[:5])))for j in range(len(raw_data[i]))]
            df_list.append(c)
            index.append(dates[k] + c[0])
            f_index = [index[i] for i in range(len(index)) if len(index[i]) > 6]
            data = [df_list[i][1:] for i in range(len(df_list)) if len(df_list[i][1:]) == 19]
    else:
        url = "http://www.estesparkweather.net/archive_reports.php?date="
        url =url+dates[k]
        page = requests.get(url)
        soup =  BeautifulSoup(page.content,'html.parser')
        table = soup.find_all('table')
        raw_data = [row.text.splitlines() for row in table]
        raw_data = raw_data[:-9]
        for i in range(len(raw_data)):
            raw_data[i] = raw_data[i][2:len(raw_data[i]):3]
    
    
        for i in range(len(raw_data)):
            c = ['.'.join(re.findall("\d+",str(raw_data[i][j].split()[:5])))for j in range(len(raw_data[i]))]
            df_list.append(c)
            index.append(dates[k] + c[0])
            f_index = [index[i] for i in range(len(index)) if len(index[i]) > 6]
            data = [df_list[i][1:] for i in range(len(df_list)) if len(df_list[i][1:]) == 19]


final_index = [datetime.datetime.strptime(str(f_index[i]), '%Y%m%d').strftime('%Y-%m-%d') for i in range(len(f_index))]
Weather_data=pd.DataFrame(data=data,columns=labels,index=final_index)
Weather_data=Weather_data.astype('float64')
Weather_data.index=Weather_data.index.astype('datetime64')




